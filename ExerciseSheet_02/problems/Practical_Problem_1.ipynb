{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed6b54-f74e-4341-bf36-10d5cc01a09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b95bf1",
   "metadata": {},
   "source": [
    "### 1. Phoneme Dataset\n",
    "Load the phoneme dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c9a895-9863-4a10-9c4b-fcc5dcb21283",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/phoneme.csv')\n",
    "print(data)\n",
    "\n",
    "# TODO \n",
    "# Split the dataset into a train and test dataset according to column \"speaker\".\n",
    "# Be sure to exclude row number, \"speaker\" and response columns from your features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1545466-f4b8-4dac-aedc-23a28aaa34ba",
   "metadata": {},
   "source": [
    "### 2. LDA modelling\n",
    "Fit an LDA model. Compute and report the train and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07740f4-6f7c-4f7f-9186-e808c6a1234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab66f56-297f-4602-aac9-bf6ea03d322a",
   "metadata": {},
   "source": [
    "### 3. LDA canonical coordinates\n",
    " Plot the projection of the training data onto the first two canonical coordinates of the LDA and report your findings. Investigate the data projected on further dimensions using the \\texttt{dimen} parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7100c5d-6304-4720-ac5b-0cba6277b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2205c6e-02cf-4228-8f81-9396308ba0f7",
   "metadata": {},
   "source": [
    "### 4. LDA on \"aa\", \"ao\"\n",
    "Select the two phonemes \"aa\" and \"ao\". Fit an LDA model on this data set and repeat the steps\n",
    "    done in (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7709f18-b292-4ae3-a13e-d0424e329ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b231d3e",
   "metadata": {},
   "source": [
    "## 5. QDA\n",
    "Repeat steps (b) and (d) using QDA and report your findings. Would you prefer LDA or QDA in this example? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52089486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d08a3",
   "metadata": {},
   "source": [
    "## 6. Confusion Matrices\n",
    "Generate confusion matrices for the LDA and QDA model for \"aa\" and \"ao\". Which differences can you observe between the models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468e438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
